<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
 <!-- 解析参数dfs.nameservices值hdfs://mycluster的地址 -->
  <property>
    <name>dfs.nameservices</name>
    <value>hdfscluster</value>
  </property>

  <!-- 指定副本的数量 -->
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>

   <!-- mycluster由以下两个namenode支撑 -->
  <property>
    <name>dfs.ha.namenodes.hdfscluster</name>
    <value>nn1,nn2</value>
  </property>

   <!-- 指定nn1 rpc 地址和端口号  -->
  <property>
    <name>dfs.namenode.rpc-address.hdfscluster.nn1</name>
    <value>node01:8020</value>
  </property>
  <!-- 指定nn2 rpc地址和端口号  -->
  <property>
    <name>dfs.namenode.rpc-address.hdfscluster.nn2</name>
    <value>node02:8020</value>
  </property>

   <!-- nn1的http通信地址-->
  <property>
    <name>dfs.namenode.http-address.hdfscluster.nn1</name>
    <value>node01:9870</value>
  </property>

    <!-- nn1的http通信地址-->
  <property>
    <name>dfs.namenode.http-address.hdfscluster.nn2</name>
    <value>node02:9870</value>
  </property>
     <!-- 指定三台journal node服务器的地址 -->
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://node04:8485;node02:8485;node03:8485/hdfscluster</value>
  </property>
  <!--jnn 存放元数据的地址-->
   <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/var/fnltestjnn/hadoop/ha/jnn</value>
  </property>

<!-- 当active nn出现故障时，ssh到对应的服务器，将namenode进程kill掉  -->
  <property>
    <name>dfs.ha.fencing.methods</name>
    <!--<value>sshfence</value>-->
    <value>shell(/bin/true)</value>
  </property>
    <!--生成的秘钥所存储的目录 -->
  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/root/.ssh/id_rsa</value>
  </property>
  <!--启动NN故障自动切换 -->
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>

<!-- 指定客户端查找active的namenode的策略：会给所有namenode发请求，以决定哪个是active的 -->
  <property>
    <name>dfs.client.failover.proxy.provider.hdfscluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
<!-- 配置namenode存储元数据的目录-->
<property>
  <name>dfs.namenode.name.dir</name>
  <value>file:///usr/namenode </value>
</property>

<!-- 配置datanode存储数据块的目录-->
<property>
  <name>dfs.datanode.data.dir</name>
  <value>file:///usr/datanode </value>
</property>


<!--设置hdfs的操作权限，设置为false表示任何用户都可以在hdfs上操作并且可以使用插件 -->
<property>
  <name>dfs.permissions</name>
  <value>false</value>
</property>
</configuration>
